---
icon: material/numeric-6
---

# Try It Yourself


## Learning Activity: Analyzing a State-of-the-Art AI Model ðŸš€

**Objective:** To apply your foundational knowledge of AI model development and multimodality to analyze a real-world product announcement. In this activity, you will act as a product manager evaluating Google's Gemini 2.5 Flash image model to develop market intelligence.


<figure markdown="span">
  [![Behind the scenes of Google's state-of-the-art "nano-banana" image model](http://img.youtube.com/vi/H6ZXujE1qBA/0.jpg)](https://www.youtube.com/watch?v=H6ZXujE1qBA)
  <figcaption>Video: Behind the scenes of Google's state-of-the-art "nano-banana" image model</figcaption>
</figure>


### Step 1: Review the Source Materials

Your task is to analyze the key capabilities of Google's Gemini 2.5 Flash model. Watching full video is optional; You can use the  video chapters and time stamps to access relevant sections.


### Step 2: Analysis Framework

Answer the following questions using the provided texts. Think critically about the connections between the technology described and the business implications.

**1. Multimodality and Embeddings:**

* The summary mentions "positive transfer between modalities" and "native multimodal understanding." Based on what you learned about embeddings in **Module 3**, how does having a single, "native" multimodal model (as opposed to separate models for text and images) lead to better performance and "positive transfer"?
* The AI excels at understanding nuanced, conversational prompts to edit images. Describe how a shared embedding space for text and images makes this possible.

**2. Model Development and Fine-Tuning (SFT):**

* The video discusses achieving "character consistency" and "pixel-perfect editing." What kind of specialized data and **Supervised Fine-Tuning (SFT)** would be required to teach a model these specific, high-level skills?
* The summary notes that user feedback from platforms like Twitter was crucial for identifying failure modes. How does this real-world feedback loop relate to the **SFT** and **Safety Tuning** processes we discussed in **Module 4**?

**3. Evaluation:**

* The team is developing metrics "beyond human preference evals," using text rendering as a proxy for quality. Why might relying solely on human preference not be enough for evaluating a model's technical capabilities? What does the ability to render text accurately suggest about the model's underlying understanding of structure?

**4. Strategic and Market Analysis:**

* The speakers contrast specialized models with Gemini's goal of being a "creative partner for complex workflows." Based on the market intelligence discussion in **Module 4**, is this a convincing **differentiator**? Why or why not?
* A new capability called "Interleaved Image Generation" is mentioned, which breaks down complex tasks into steps. How does this feature create business value for a creative professional (e.g., a marketer or designer)?

## Helpful Tips and Suggestions

* **Focus on the "Why":** Don't just list the features. Your goal is to explain *why* these features are significant, based on the foundational concepts from our modules.
* **Think Like a PM:** For each capability, ask yourself: What business problem does this solve? Who is the target user? What are the risks?
* **Use Course Terminology:** Actively use terms like **embedding**, **multimodality**, **SFT**, **evaluation**, and **differentiator** in your answers to demonstrate your understanding.
* **Reference the Timestamps:** If you want to quickly see a feature in action, use the timestamps in the video description to jump to the relevant demo.